{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first ML model\n",
    "\n",
    "As we saw on the previous notebook, there are about 80 different variables (features) we can use to train our model. Which ones should we use? There are techniques to help with this **feature selection**. For now, let's start by using our intuition, and start with a small selection of features that we think will help the model learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't modify\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/housing/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the attribute `columns` in the DataFrame to print the list of available features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = # your answer here\n",
    "print(f'Available features: {columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "The columns that are inputted into our model (and later used to make predictions) are called **features**. In our case, those would be the columns used to determine the home price. Sometimes, you will use all columns except the target as features. Other times you'll be better off with fewer features.\n",
    "\n",
    "We can start simple by selecting a small subset of all the above features. A subset of data that could make sense is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'LotArea',\n",
    "    'YearBuilt',\n",
    "    '1stFlrSF',\n",
    "    '2ndFlrSF',\n",
    "    'FullBath',\n",
    "    'BedroomAbvGr',\n",
    "    'TotRmsAbvGrd'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features are, respectively:\n",
    "\n",
    "* The size in square feet\n",
    "* The year when the house was built\n",
    "* First floor square feet\n",
    "* Second floor square feet\n",
    "* Full bathrooms above grade\n",
    "* Bedrooms above grade (does NOT include basement bedrooms)\n",
    "* Total rooms above grade (does not include bathrooms)\n",
    "\n",
    "These features should have enough **predictive power** on the final price. That is what we want to predict, and what we call **target** variable. Looking at all the columns, which one do you think is our target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '' # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new variables: \n",
    "\n",
    "* `X`: A DataFrame with _only_ the subset of selected columns\n",
    "* `y`: A DataFrame with _only_ the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  # your answer here\n",
    "y =  # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with missing data**\n",
    "\n",
    "For simplicity, we have selected a list of columns that do **not** have any missing value.\n",
    "\n",
    "However, we saw before that some columns had mising values (`NaN`s, values that were not recorder). Algorithms don't understand what a `NaN` is, so we need to do something with those samples. There are several options:\n",
    "\n",
    "1. Average the value over the rest of the sample or any other statistic (median, min, etc)\n",
    "2. Try to infer the value from other columns (if that would be a derived value)\n",
    "3. Drop samples with `NaN` values.\n",
    "\n",
    "Depending of the feature and amount of missing values, one option may be better than another. For now though, we don't have to worry about this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review the data**\n",
    "\n",
    "Before continuing further, review X to make sure it makes sense.\n",
    "\n",
    "Print the descriptive statistics of X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our model\n",
    "You will use the `scikit-learn` library to create your models. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n",
    "\n",
    "The steps to building and using a model are:\n",
    "\n",
    "* **Define**: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n",
    "* **Fit**: Capture patterns from provided data. This is the heart of modeling.\n",
    "* **Predict**: Just what it sounds like\n",
    "* **Evaluate**: Determine how accurate the model's predictions are.\n",
    "\n",
    "Let's try this with our subset of the data!\n",
    "\n",
    "First of all, we need to import the class `DecisionTreeRegressor` from `sklearn.tree` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we instanciate the model, and fit it. In order to train, we need to provide the model with two parameters: A list of samples and their true value `(X, y)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = # Instanciate the model\n",
    "\n",
    "model. # fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think all those parameters are?\n",
    "\n",
    "Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. This is considered a good practice. You use any number, and model quality won't depend meaningfully on exactly what value you choose.\n",
    "\n",
    "We now have a fitted model that we can use to make predictions.\n",
    "\n",
    "In practice, you'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But we'll make predictions for the first few rows of the training data to see how the predict function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5 = X.head()\n",
    "predictions = # your answer here\n",
    "first_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Predictions are {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `head` method to compare your predictions with the first 5 true values in `y`. Anything surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 true values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
