{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "> Some of the explanations in this tutoarial are inspired by chapters 3 and 8 in the book _\"Python Machine Learning\"_ by Sebastian Raschka\n",
    "\n",
    "First, let's introduce what Logistic Regression is. \n",
    "\n",
    "[Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) is a classification model that is very easy to implement and performs very well on linearly separable classes. It is one of the most widely used\n",
    "algorithms for classification in industry too, which makes it attractive to play with.\n",
    "\n",
    "_Very_ simplistically explained, Logistic Regression works as follows:\n",
    "\n",
    "![Logistic Regression](../data/misc/logistic_regression.png)\n",
    "\n",
    "First we will define the input for our algorithm. The imput will be each sample in whatever dataset we are working with. Each sample will consist of several features. For example, if we're working with housing price prediction, the features for each sample could be the size of the house, number of rooms, etc. We'll call the input vector **X**.\n",
    "\n",
    "For the algorythm to learn, we need to define variables that we can adjust accordingly to what we want to predict. We will create a vector of _weights_ (**W**) that the model will adjust in order to predict more accurately. The process of adjusting those weights is what we call **learning**.\n",
    "\n",
    "For every input sample, we will perform a dot product of the features by the weights **XW**. This product is sometimes referred as _net input_. This will give us a real number. Since in this particular problem we want to _classify_ (positive/negative), we need squash this number in the range [0, 1]. This will give us the _probability_ of a positive event. A function that does precisely that is called **sigmoid**. The sigmoid function looks like this:\n",
    "\n",
    "![sigmoid](../data/misc/sigmoid.svg)\n",
    "\n",
    "What sigmoid is doing is basically transforming big inputs into a value close to 1, and small inputs into a value close to 0. This is exactly what we want. \n",
    "\n",
    "We will do this for every sample in our training set and compute the errors. To calculate the error we only need to compare our prediction with the true label for each sample. We will sum the square errors of all the samples to get a global prediction error. This will be our **cost function**.\n",
    "\n",
    "A cost function is then something we want to minimize. **Gradient descent** is a method for finding the minimum of a function of multiple variables, such like the one we're dealing with here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient descent\n",
    "\n",
    "> Watch [this](https://www.youtube.com/watch?v=IHZwWFHWa-w) video for a visual introduction to Gradient Descent\n",
    "\n",
    "Once all our training samples have been computed and the error calculated with our cost function, we need to _minimize_ that cost function. A method for doing that is gradient descent. There are many [articles](https://en.wikipedia.org/wiki/Gradient_descent) that contain detailed explanations _and_ implementations of GD, so let's not do this here. However is good to have an intuition.\n",
    "\n",
    "For illustration purposes, let's think about a function with two parameters. Something like this one:\n",
    "\n",
    "![Gradient Descent](../data/misc/Gradient_descent.png)\n",
    "\n",
    "Gradient descent will try to find the minimum of the function. To do so, we calculate the slope of the function at a certain point, and move towards the direction that makes the function decrease. There are some things to have in mind though.\n",
    "\n",
    "As you can see a function can have one or several _local minimum_. In a local minimum, the slope will be zero and GD will \"think\" it's found the global minimum. To avoid this, we can choose a bigger \"step\" when we move towards the minimum. The \"size\" of the step towards the minimun is what we call the **learning rate**, and it's another adjustable parameter.\n",
    "\n",
    "We need to be careful here: If we choose a too small learning rate, we can get stuck in a local minimum. If we instead choose a too big learning rate, we risk overshooting the global minimum. We need to experiment, and the adecuate learning rate depends on the particular problem and the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training process\n",
    "\n",
    "In order for logistic regression to learn, we need to repeat the process descrived before several times. Each one of these times is called an **epoch**. The number of epochs to run depends on the problem and the training data. It is... yes, another tunnable parameter of the algorithm.\n",
    "\n",
    "The set of all tunnable parameters is called **hyperparameters** of the model.\n",
    "\n",
    "Like with the leatning rate, we need to be careful when choosing the number of epochs: If we train too many epochs, we risk **overfitting**. This means that our model will \"memorize\" the training data and will generalize badly when presented new data. \n",
    "\n",
    "If we train too little, it will fail to find any pattern and the prediction accuracy will be very low. This is known as **underfitting**.\n",
    "\n",
    "There are techniques that help prevent overfitting. These **regularization** techniques are out of the scope of this tutorial, but... guess! It's also something to tune and experiment with :)\n",
    "\n",
    "This is why when training a model you need to set aside a _test dataset_ in order to know the accuracy of your algorithm in unknown data. The test dataset will **never** be used during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "Let's first of all have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ...\n",
       "5       6          0                  or i just worry too much?        \n",
       "6       7          1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
       "7       8          0         Sunny Again        Work Tomorrow  :-|  ...\n",
       "8       9          1        handed in my uniform today . i miss you ...\n",
       "9      10          1           hmmmm.... i wonder how she my number @-)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the data into a DataFrame\n",
    "train = pd.read_csv('../data/twitter/train.csv', encoding='latin-1')\n",
    "test = pd.read_csv('../data/twitter/test.csv', encoding='latin-1')\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the structure of a twit varies a lot between twit and twit. They have different lengths, letters, numbers, extrange characters, etc. \n",
    "\n",
    "It is also important to note that **a lot** of words are not correctly spelled, for example the word _\"Juuuuuuuuuuuuuuuuussssst\"_ or the word _\"frie\"_ instear of _\"friend\"_\n",
    "\n",
    "This makes it hard to mesure how positive or negative are the words withing the corpus of twits. If they were all correct dictionary words, we could use a **lexicon** to punctuate words. However because of the nature of social media language, we cannot do that. \n",
    "\n",
    "So we need a way of scoring the words such that words that appear in positive twits have greater score that those that appear in negative twits.\n",
    "\n",
    "But first... how do we represent the twits as vectors we can input to our algorithm?\n",
    "\n",
    "### Bag of words\n",
    "\n",
    "One thing we could do to represent the twits as equal-sized vectors of numbers is the following:\n",
    "\n",
    "* Create a list (vocabulary) with all the unique words in the whole corpus of twits. \n",
    "* We construct a feature vector from each twit that contains the counts of how often each word occurs in the particular twit\n",
    "\n",
    "_Note that since the unique words in each twit represent only a small subset of all the words in the bag-of-words vocabulary, the feature vectors will mostly consist of zeros_\n",
    "\n",
    "Let's construct the bag of words. We will work with a smaller example for illustrative purposes, and at the end we will work with our real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'amazing': 2,\n",
       " 'ml': 9,\n",
       " 'the': 12,\n",
       " 'best': 3,\n",
       " 'yes': 15,\n",
       " 'it': 8,\n",
       " 'am': 1,\n",
       " 'not': 10,\n",
       " 'sure': 11,\n",
       " 'about': 0,\n",
       " 'how': 6,\n",
       " 'going': 5,\n",
       " 'to': 14,\n",
       " 'end': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "twits = [\n",
    "    'This is amazing!',\n",
    "    'ML is the best, yes it is',\n",
    "    'I am not sure about how this is going to end...'\n",
    "]\n",
    "\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(twits)\n",
    "\n",
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from executing the preceding command, the vocabulary is stored in a Python dictionary that maps the unique words to integer indices. Next, let's print the feature vectors that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each index position in the feature vectors corresponds to the integer values that are stored as dictionary items in the CountVectorizer vocabulary. For example, the first feature at index position 0 resembles the count of the word 'about' , which only occurs in the last document, and the word 'is' , at index position 7, occurs in all three twits (two times in the second twit). These values in the feature vectors are also called the **raw term frequencies**: `tf(t,d )` â€”the number of times a term `t` occurs in a document `d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How relevant are words? Term frequency-inverse document frequency\n",
    "\n",
    "We could use these raw term frequencies to score the words in our algorithm. There is a problem though: If a word is very frequent in _all_ documents, then it probably doesn't carry a lot of information. In order to tacke this problem we can use **term frequency-inverse document frequency**, which will reduce the score the more frequent the word is accross all twits. It is calculated like this:\n",
    "\n",
    "\\begin{equation*}\n",
    "tf-idf(t,d) = tf(t,d) ~ idf(t,d)\n",
    "\\end{equation*}\n",
    "\n",
    "_tf(t,d)_ is the raw term frequency descrived above. _idf(t,d)_ is the inverse document frequency, than can be calculated as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\log \\frac{n_d}{1+df\\left(d,t\\right)}\n",
    "\\end{equation*}\n",
    "\n",
    "where `n` is the total number of documents and _df(t,d)_ is the number of documents where the term `t` appears. \n",
    "\n",
    "The `1` addition in the denominator is just to avoid zero term for terms that appear in all documents. Ans the `log` ensures that low frequency term don't get too much weight.\n",
    "\n",
    "Fortunately for us `scikit-learn` does all those calculations for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.72, 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.55, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.4 , 0.  , 0.  , 0.  , 0.47, 0.4 , 0.4 , 0.  ,\n",
       "        0.  , 0.4 , 0.  , 0.  , 0.4 ],\n",
       "       [0.33, 0.33, 0.  , 0.  , 0.33, 0.33, 0.33, 0.2 , 0.  , 0.  , 0.33,\n",
       "        0.33, 0.  , 0.25, 0.33, 0.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True,\n",
    "                         norm='l2',\n",
    "                         smooth_idf=True)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Feed the tf-idf transformer with our previously created Bag of Words\n",
    "tfidf.fit_transform(bag).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, words that appear in all documents like _is_ (with 0.47 ), get a lower score than others that don't appear in all documents, like _amazing_ (with 0.72).\n",
    "\n",
    "Note also that `norm='l2'` parameter: This is an important one, and what is doing is normalize the tf-idfs so that they're all in the same scale and thus work better with Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean up (yay...)\n",
    "\n",
    "### Removing stop words\n",
    "\n",
    "Now that we know how to format and score our input, we can start doing the analysis! Can we?... Well, we _can_, but let's look at our **real** vocabulary. Specifically, the most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 123916),\n",
       " ('I', 32879),\n",
       " ('to', 28810),\n",
       " ('the', 28087),\n",
       " ('a', 21321),\n",
       " ('you', 21180),\n",
       " ('i', 15995),\n",
       " ('and', 14565),\n",
       " ('it', 12818),\n",
       " ('my', 12385),\n",
       " ('for', 12149),\n",
       " ('in', 11199),\n",
       " ('is', 11185),\n",
       " ('of', 10326),\n",
       " ('that', 9181),\n",
       " ('on', 9020),\n",
       " ('have', 8991),\n",
       " ('me', 8255),\n",
       " ('so', 7612),\n",
       " ('but', 7220)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter()\n",
    "for twit in train.SentimentText:\n",
    "    for word in twit.split(' '):\n",
    "        vocab[word] += 1\n",
    "\n",
    "vocab.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the most common words are meaningless in terms of sentiment: _I, to, the, and_... they don't give any information on positiveness or negativeness. They're basically **noise** that can most probably be eliminated. Let's see the whole distribution to convince ourselves of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"9c60aa3b-5cac-4cd1-885d-e3cd30bcde4e\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"8860338e-bcd7-4a1d-8af6-f4db344f9eef\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1022\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1018\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1035\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1003\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"1039\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"SaveTool\"},{\"attributes\":{\"text\":\"Word distribution accross all twits\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1023\",\"type\":\"PanTool\"},{\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"SaveTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[500]},\"right\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[500]},\"top\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[500]}},\"selected\":{\"id\":\"1043\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1042\",\"type\":\"UnionRenderers\"}},\"id\":\"1032\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1039\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"PanTool\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"}},\"id\":\"1036\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1033\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1034\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1036\",\"type\":\"CDSView\"}},\"id\":\"1035\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1033\",\"type\":\"Quad\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1034\",\"type\":\"Quad\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"8860338e-bcd7-4a1d-8af6-f4db344f9eef\",\"roots\":{\"1002\":\"9c60aa3b-5cac-4cd1-885d-e3cd30bcde4e\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def plot_distribution(vocabulary):\n",
    "\n",
    "    hist, edges = np.histogram(list(map(lambda x:math.log(x[1]),vocabulary.most_common())), density=True, bins=500)\n",
    "\n",
    "    p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "               toolbar_location=\"above\",\n",
    "               title=\"Word distribution accross all twits\")\n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\", )\n",
    "    show(p)\n",
    "\n",
    "plot_distribution(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear now that a porcion of the words are overly represented. These kind of words are called _stop words_, and it is a common practice to remove them when doing text analysis. Let's do it and see the distribution again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/guillermo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 123916),\n",
       " ('I', 32879),\n",
       " (\"I'm\", 6416),\n",
       " ('like', 5086),\n",
       " ('-', 4922),\n",
       " ('get', 4864),\n",
       " ('u', 4194),\n",
       " ('good', 3953),\n",
       " ('love', 3494),\n",
       " ('know', 3472),\n",
       " ('go', 2990),\n",
       " ('see', 2868),\n",
       " ('one', 2787),\n",
       " ('got', 2774),\n",
       " ('think', 2613),\n",
       " ('&amp;', 2556),\n",
       " ('lol', 2419),\n",
       " ('going', 2396),\n",
       " ('really', 2287),\n",
       " ('im', 2200)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "vocab_reduced = Counter()\n",
    "for w, c in vocab.items():\n",
    "    if not w in stop:\n",
    "        vocab_reduced[w]=c\n",
    "\n",
    "vocab_reduced.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better, only in the 20 most common words we already see words that make sense: _good, love, really_... Let's see the distribution now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"501002b2-0d67-4b3c-a113-abc6cb044120\" data-root-id=\"1086\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"a29b78b5-cc75-4f46-be6c-3269b91b3684\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1097\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1101\",\"type\":\"Grid\"},{\"id\":\"1106\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1102\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1119\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1087\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1111\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1089\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1093\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1091\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1095\",\"type\":\"LinearScale\"}},\"id\":\"1086\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1134\",\"type\":\"Selection\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1103\",\"type\":\"BasicTicker\"}},\"id\":\"1106\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1091\",\"type\":\"DataRange1d\"},{\"attributes\":{\"ticker\":{\"id\":\"1098\",\"type\":\"BasicTicker\"}},\"id\":\"1101\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1089\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1130\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1132\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1103\",\"type\":\"BasicTicker\"}},\"id\":\"1102\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1108\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1098\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1132\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1093\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1107\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1110\",\"type\":\"SaveTool\"},{\"attributes\":{\"text\":\"Word distribution accross all twits\"},\"id\":\"1087\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[500]},\"right\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[500]},\"top\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[500]}},\"selected\":{\"id\":\"1134\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1133\",\"type\":\"UnionRenderers\"}},\"id\":\"1116\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1109\",\"type\":\"ResetTool\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1117\",\"type\":\"Quad\"},{\"attributes\":{\"formatter\":{\"id\":\"1130\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1098\",\"type\":\"BasicTicker\"}},\"id\":\"1097\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1133\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"1116\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1117\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1118\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1120\",\"type\":\"CDSView\"}},\"id\":\"1119\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1118\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1103\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1095\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"1116\",\"type\":\"ColumnDataSource\"}},\"id\":\"1120\",\"type\":\"CDSView\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1107\",\"type\":\"PanTool\"},{\"id\":\"1108\",\"type\":\"WheelZoomTool\"},{\"id\":\"1109\",\"type\":\"ResetTool\"},{\"id\":\"1110\",\"type\":\"SaveTool\"}]},\"id\":\"1111\",\"type\":\"Toolbar\"}],\"root_ids\":[\"1086\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"a29b78b5-cc75-4f46-be6c-3269b91b3684\",\"roots\":{\"1086\":\"501002b2-0d67-4b3c-a113-abc6cb044120\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1086"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(vocab_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing special characters and \"trash\"\n",
    "\n",
    "We still se a very uneaven distribution. If you look closer, you'll see that we're also taking into consideration punctuation signs ('-', ',', etc) and other html tags like `&amp`. We can definitely remove them for the sentiment analysis, but we will try to keep the emoticons, since those _do_ have a sentiment load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this twit man is nice :)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(preprocessor('This!! twit man :) is <b>nice</b>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready! There is another trick we can use to reduce our vocabulary and consolidate words. If you think about it, words like: love, loving, etc. _Could_ express the same positivity. If that was the case, we would be  having two words in our vocabulary when we could have only one: lov. This process of reducing a word to its root is called **steaming**.\n",
    "\n",
    "We also need a _tokenizer_ to break down our twits in individual words. We will implement two tokenizers, a regular one and one that does steaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
      "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
    "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logistic Regression\n",
    "\n",
    "We are finally ready to train our algorythm. We need to choose the best hyperparameters like the _learning rate_ or _regularization strength_. We also would like to know if our algorithm performs better steaming words or not, or removing html or not, etc...\n",
    "\n",
    "To take these decisions methodically, we can use a Grid Search. Grid search is a method of training an algorythm with different variations of parameters to latter select the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset in train and test\n",
    "X = train['SentimentText']\n",
    "y = train['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code line above, `stratify` will create a train set with the same class balance than the original set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__preprocessor': [None, preprocessor],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__preprocessor': [None, preprocessor],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d3c8e8bc2fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loky'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgs_lr_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/ml-workshop/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note: This may take a long while to execute, like... 1 or 2 hours\n",
    "from sklearn.utils import parallel_backend\n",
    "\n",
    "with parallel_backend('loky', n_jobs=-1):\n",
    "    gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__C': 1.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__preprocessor': <function preprocessor at 0x7f8daa8109d8>, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f8da0c3d378>}\n",
      "Best accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: ' + str(gs_lr_tfidf.best_params_))\n",
    "print('Best accuracy: %.3f' % gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the set of parameters that best results give us are:\n",
    "\n",
    "* A regularization strength of `1.0` using `l2` regularization\n",
    "* Using our `preprocessor` (removing html, keeping emoticons, etc) _does_ improve the performance\n",
    "* Surprisingly, removing stop words does not improve accuracy\n",
    "* word steming doesn't seem to help either\n",
    "\n",
    "As youcan see, sometimes intuition may lead to wrong decisions, and it's important to _test_ all our assumptions. \n",
    "\n",
    "Let's see what's our best accuracy then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in test: 0.770\n"
     ]
    }
   ],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Accuracy in test: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would like to use the classifier in another place, or just not train it again and again everytime, we can save the model in a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "pickle.dump(clf, open(os.path.join('data', 'logisticRegression.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run some tests :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is really bad, I don't like it at all --> 0\n",
      "I love this! --> 1\n",
      ":) --> 1\n",
      "I'm sad... :( --> 0\n"
     ]
    }
   ],
   "source": [
    "twits = [\n",
    "    \"This is really bad, I don't like it at all\",\n",
    "    \"I love this!\",\n",
    "    \":)\",\n",
    "    \"I'm sad... :(\"\n",
    "]\n",
    "\n",
    "preds = clf.predict(twits)\n",
    "\n",
    "for i in range(len(twits)):\n",
    "    print(f'{twits[i]} --> {preds[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
